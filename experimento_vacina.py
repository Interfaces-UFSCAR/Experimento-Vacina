# -*- coding: utf-8 -*-
"""Experimento_vacina.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Uj-HgO5Gl9LGn9-v9nuWo3olVGYbEbZD

# Preprocessing
"""

from google.colab import files
import io
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
from sklearn.feature_selection import RFECV
import numpy as np
import statsmodels.api as sm
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression

from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, RandomForestRegressor
from sklearn.metrics import roc_auc_score
from sklearn.feature_selection import SelectFromModel, SequentialFeatureSelector

import warnings
warnings.filterwarnings("ignore")

"""## File upload"""

#Repositório do experimento: "Google Drive"
#Diretório: "Projeto_Vacina"
uploaded = files.upload() #Arquivo usado no experimento: "output_file.csv"
path = list(uploaded.keys())[0]
uploaded_df = pd.read_csv(io.BytesIO(uploaded[path]))

df = uploaded_df.copy()

df.head()

"""## Column drop"""

df.drop(columns=['FXIDADE','P2A','P1B','P2B01','P2B02','P2B03','P3B01','P3B02',
                 'P3B03','P1C01','P1C02','P1C03','P1C04','P1C05','P1C06',
                 'P1C07','P2C01', 'P2C02', 'P2C03', 'P2C04', 'P2C05',
                 'P3C01', 'P3C02','P3C03', 'P3C04','P4C01', 'P4C02',
                 'P5C01', 'P5C02', 'P5C03', 'P5C04','P5C05',
                 'P6C01', 'P6C02', 'P6C03', 'P6C04', 'P6C05', 'P6C06', 'P6C07',
                 'P7C01', 'P7C02', 'P7C03', 'P7C04', 'P7C05','P8C01',
                 'P8C02', 'P8C03', 'P8C04', 'P8C05', 'P8C06','P9C03','P10C01',
                 'COND', 'PORTE', 'SbjNum', 'TIPO_COLETA','DATA_ENTREVISTA'], inplace=True)

"""## Data wrangling"""

df['FXIDADE'] = pd.qcut(x=df['IDADE'], q=[0, .25, .5, .75, 1.], labels=['16_A_28','29_A_41','42_A_54','54_MAIS'])
df['FXIDADE'].value_counts()

df['ESCOLARIDADE'].value_counts()

escolaridade_mapping = {'Analfabeto':'ANALFABETO',
              'Sabe ler/ escrever, mas não cursou escola':'ANALFABETO',
              'Pré-escola (ou 1º ano)':'ANALFABETO',
              '1ª série':'FUNDAMENTAL_1',
              '1ª série (ou 2º ano)':'FUNDAMENTAL_1',
              '2ª série':'FUNDAMENTAL_1',
              '2ª série (ou 3º ano)':'FUNDAMENTAL_1',
              '3ª série':'FUNDAMENTAL_1',
              '3ª série (ou 4º ano)':'FUNDAMENTAL_1',
              '4ª série (ou 5º ano)':'FUNDAMENTAL_1',
              '5ª série (ou 6º ano)':'FUNDAMENTAL_2',
              '6ª série (ou 7º ano)':'FUNDAMENTAL_2',
              '7ª série (ou 8º ano)':'FUNDAMENTAL_2',
              '8ª série (ou 9º ano)':'FUNDAMENTAL_2',
              'Superior incompleto':'SUPERIOR_INCOMPLETO',
              'Superior completo':'SUPERIOR_COMPLETO'}

df['ESCOLARIDADE'] = df['ESCOLARIDADE'].map(escolaridade_mapping)

df['P1A01'].value_counts()

p1_mapping = {'Não votaria nele(a) de jeito nenhum para Presidente da República':0,
              'Não o(a) conhece o suficiente para opinar':0,
              'Não sabe/ Não respondeu':0,
              'Poderia votar nele(a) para Presidente da República':1,
              'Com certeza votaria nele(a) para Presidente da República':1}

p1_columns = ['P1A01','P1A02', 'P1A03', 'P1A04', 'P1A05', 'P1A06', 'P1A07', 'P1A08', 'P1A09','P1A10']

for column in p1_columns:
  df[column] = df[column].map(p1_mapping)

df['P9C01'].value_counts()

p9c01_mapping = {'Não sabe/ Não respondeu':0,
              'Não concorda, nem discorda (Esp.)':0,
              'Discorda totalmente':0,
              'Discorda em parte':0,
              'Concorda em parte':1,
              'Concorda totalmente':1}

df['P9C01'] = df['P9C01'].map(p9c01_mapping)

df['P9C02'].value_counts() # variavel Y

p9c02_mapping = {'Não sabe/ Não respondeu':0,
             'Não concorda, nem discorda (Esp.)':0,
             'Discorda totalmente':0,
             'Discorda em parte':0,
             'Concorda em parte':0,
             'Concorda totalmente':1} # pro-vac

df['P9C02'] = df['P9C02'].map(p9c02_mapping)

df['P3A'].value_counts()

p3_mapping = {'Não sabe/ Não respondeu':0,
              'Desaprova':0,
              'Aprova':1}

df['P3A'] = df['P3A'].map(p3_mapping)

df['P4A'].value_counts()

p4_mapping = {'Não sabe/ Não respondeu':0,
              'Não confia':0,
              'Confia':1}

df['P4A'] = df['P4A'].map(p4_mapping)

df['P10C02'].value_counts()

p10_mapping = {'Não sabe/ Não respondeu':0,
              'Não concorda, nem discorda (Esp.)':0,
              'Discorda totalmente':0,
              'Discorda em parte':0,
              'Concorda em parte':1,
              'Concorda totalmente':1}

p10_columns = ['P10C02','P10C03','P10C04','P10C05','P10C06']

for column in p10_columns:
  df[column] = df[column].map(p10_mapping)

df['REND1'].value_counts()

df['REND2'].value_counts()

rend_mapping = {'NÃO TEM RENDIMENTO PESSOAL':'SEM_RENDA_PESSOAL',
              'ATÉ 1':'ATE_1',
              'MAIS DE 1 A 2':'1_A_2',
              'MAIS DE 2 A 5':'2_A_5',
              'MAIS DE 5 A 10':'5_MAIS',
              'MAIS DE 10 A 20':'5_MAIS',
              'MAIS DE 20':'5_MAIS',
              'NÃO RESPONDEU': 'N/A'}

rend_columns = ['REND1','REND2']

for column in rend_columns:
  df[column] = df[column].map(rend_mapping)

df['REG'].value_counts()

reg_mapping = {'NORTE/ CENTRO OESTE':'NORTE_CENTRO_OESTE',
               'SUDESTE':'SUDESTE',
               'NORDESTE':'NORDESTE',
               'SUL':'SUL'}

df['REG'] = df['REG'].map(reg_mapping)

df['RELIGIAO'].value_counts()

religiao_mapping = {'Católica Apostólica Romana':'CATOLICA',
               'Assembléia de Deus':'EVANGELICA',
               'Ateu, não tem religião':'ATEU',
               'Outras Evangélicas específicas':'EVANGELICA',
               'Evangélica - Não sabe especificar':'EVANGELICA',
               'É religioso mas não segue nenhuma/ Agnóstico':'AGNOSTICO',
               'Batista/ Metodista/ Presbiteriana':'EVANGELICA',
               'Espírita/ Kardecista':'ESPIRITA',
               'Evangelho Quadrangular':'EVANGELICA',
               'Afro-Brasileiras (Umbanda, Candomblé, etc)':'AFRO_BRASILEIRAS',
               'Universal do Reino de Deus':'EVANGELICA',
               'Não respondeu':'N/A',
               'Outras religiões':'OUTRAS',
               'Adventista':'EVANGELICA',
               'Testemunha de Jeová':'OUTRAS',
               'Deus é Amor':'EVANGELICA',
               'Igreja Internacional da Graça':'EVANGELICA',
               'Renascer em Cristo':'EVANGELICA',
               'Orientais (Budismo, Islamismo, etc)':'OUTRAS',
               'Sara nossa terra':'EVANGELICA'}

df['RELIGIAO'] = df['RELIGIAO'].map(religiao_mapping)

"""## Dataframe backup"""

df_tratado = df.copy()
df_renomeado = df.copy()

"""## Dataframe column rename"""

# renomear as colunas
column_names = {'REND1':'RENDA_PESSOAL',
              'REND2':'RENDA_FAMILIAR',
              'P1A01':'VOTO_CIRO',
              'P1A02':'VOTO_HADDAD',
              'P1A03':'VOTO_LULA',
              'P1A04':'VOTO_HUCK',
              'P1A05':'VOTO_BOLSONARO',
              'P1A06':'VOTO_DORIA',
              'P1A07':'VOTO_MORO',
              'P1A08':'VOTO_MANDETTA',
              'P1A09':'VOTO_BOULOS',
              'P1A10':'VOTO_MARINA',
              'P3A':'APROVA_GOVERNO',
              'P4A':'CONFIA_BOLSONARO',
              'P9C01':'VACINA_SEGURA',
              'P9C02':'VAI_VACINAR', # target
              'P10C02':'TRAT_MAIS_EFIC',
              'P10C03':'MUDA_DNA',
              'P10C04':'MICROCHIP',
              'P10C05':'CANCER_AUT_HIV',
              'P10C06':'ABORTADOS_E_TUMORES'}

df_renomeado.rename(columns=column_names, inplace=True)

"""## Dataframe split"""

df_perfil = df_renomeado[['IDADE', 'FXIDADE', 'SEXO', 'ALFABETIZACAO', 'ESCOLARIDADE','RELIGIAO', 'RENDA_PESSOAL','RENDA_FAMILIAR', 'REG', 'VAI_VACINAR']]
df_ideologia = df_renomeado[['VOTO_CIRO', 'VOTO_HADDAD', 'VOTO_LULA', 'VOTO_HUCK', 'VOTO_BOLSONARO','VOTO_DORIA', 'VOTO_MORO', 'VOTO_MANDETTA', 'VOTO_BOULOS','VOTO_MARINA','VAI_VACINAR']]
df_avaliacao_governo = df_renomeado[['APROVA_GOVERNO', 'CONFIA_BOLSONARO','VAI_VACINAR']]
df_opiniao_vacina = df_renomeado[['VACINA_SEGURA','TRAT_MAIS_EFIC', 'MUDA_DNA', 'MICROCHIP','CANCER_AUT_HIV', 'ABORTADOS_E_TUMORES','VAI_VACINAR']]

"""## Dataframe dummies


"""

df_renomeado_dummies = df_renomeado.copy()
df_renomeado_dummies = pd.get_dummies(df_renomeado_dummies, columns=["FXIDADE"], prefix=["FXIDADE"], drop_first=True)
df_renomeado_dummies = pd.get_dummies(df_renomeado_dummies, columns=["SEXO"], prefix=["SEXO"], drop_first=True)
df_renomeado_dummies = pd.get_dummies(df_renomeado_dummies, columns=["ALFABETIZACAO"], prefix=["ALFABETIZACAO"], drop_first=True)
df_renomeado_dummies = pd.get_dummies(df_renomeado_dummies, columns=["ESCOLARIDADE"], prefix=["ESCOLARIDADE"], drop_first=True)
df_renomeado_dummies = pd.get_dummies(df_renomeado_dummies, columns=["RELIGIAO"], prefix=["RELIGIAO"], drop_first=True)
df_renomeado_dummies = pd.get_dummies(df_renomeado_dummies, columns=["RENDA_PESSOAL"], prefix=["RENDA_PESSOAL"], drop_first=True)
df_renomeado_dummies = pd.get_dummies(df_renomeado_dummies, columns=["RENDA_FAMILIAR"], prefix=["RENDA_FAMILIAR"], drop_first=True)
df_renomeado_dummies = pd.get_dummies(df_renomeado_dummies, columns=["REG"], prefix=["REG"], drop_first=True)
df_renomeado_dummies

df_perfil_dummies = df_perfil.copy()
df_perfil_dummies = pd.get_dummies(df_perfil_dummies, columns=["FXIDADE"], prefix=["FXIDADE"], drop_first=True)
df_perfil_dummies = pd.get_dummies(df_perfil_dummies, columns=["SEXO"], prefix=["SEXO"], drop_first=True)
df_perfil_dummies = pd.get_dummies(df_perfil_dummies, columns=["ALFABETIZACAO"], prefix=["ALFABETIZACAO"], drop_first=True)
df_perfil_dummies = pd.get_dummies(df_perfil_dummies, columns=["ESCOLARIDADE"], prefix=["ESCOLARIDADE"], drop_first=True)
df_perfil_dummies = pd.get_dummies(df_perfil_dummies, columns=["RELIGIAO"], prefix=["RELIGIAO"], drop_first=True)
df_perfil_dummies = pd.get_dummies(df_perfil_dummies, columns=["RENDA_PESSOAL"], prefix=["RENDA_PESSOAL"], drop_first=True)
df_perfil_dummies = pd.get_dummies(df_perfil_dummies, columns=["RENDA_FAMILIAR"], prefix=["RENDA_FAMILIAR"], drop_first=True)
df_perfil_dummies = pd.get_dummies(df_perfil_dummies, columns=["REG"], prefix=["REG"], drop_first=True)
df_perfil_dummies

"""# Feature selection

## OLS Regression

### df_perfil

### df_ideologia

### df_avaliacao_governo

### df_opiniao_vacina

## WoE Analysis
"""

# adiciona uma coluna apenas para fazer um count
frames = [df_perfil, df_ideologia, df_avaliacao_governo, df_opiniao_vacina]

for frame in frames:
  frame['frequency'] = 1

"""### df_perfil"""

df_perfil_woe = pd.DataFrame(columns=['Variable', 'Value', 'X Frequency', 'Y Frequency', 'Rate', '% X', '% Y', '% Not Y', 'Risk Ratio', 'WoE', 'IV'])

# variables = df_perfil.columns.to_list()
# variables.remove('frequency')
# variables.remove('VAI_VACINAR')
variables = ['FXIDADE', 'SEXO', 'ESCOLARIDADE', 'RELIGIAO', 'RENDA_PESSOAL', 'REG','RENDA_FAMILIAR']

for var in variables:
    aux = df_perfil.groupby(by=var,as_index=False).agg({'frequency':'count','VAI_VACINAR':'sum'})
    x_frequency = aux['frequency'].sum()
    y_frequency = aux['VAI_VACINAR'].sum()
    not_y_frequency = x_frequency - y_frequency
    aux['Rate'] = aux['VAI_VACINAR'] / aux['frequency']
    aux['% X'] = aux['frequency']/x_frequency
    aux['% Y'] = aux['VAI_VACINAR']/y_frequency
    aux['% Not Y'] = (aux['frequency'] - aux['VAI_VACINAR'])/not_y_frequency
    aux['Risk Ratio'] = aux['% Y'] / aux['% Not Y']
    aux['WoE'] = np.log(aux['Risk Ratio'])
    aux['IV'] = ((1-aux['Rate']) - aux['Rate']) * aux['WoE']
    aux['Variable'] = var
    column_names = ['Variable', 'frequency', 'VAI_VACINAR', 'Rate', '% X', '% Y', '% Not Y', 'Risk Ratio', 'WoE', 'IV']
    column_names.insert(1,var)
    aux = aux[column_names]
    aux.columns = ['Variable', 'Value', 'X Frequency', 'Y Frequency', 'Rate', '% X', '% Y', '% Not Y', 'Risk Ratio', 'WoE', 'IV']
    df_perfil_woe = df_perfil_woe.append(aux, ignore_index=True)

df_perfil_woe.sort_values(by=['Variable', 'WoE'], ascending=[True, False]).reset_index(drop=True)

cols_aux = df_perfil_woe["Variable"].drop_duplicates()

for i in cols_aux:
  display(df_perfil_woe.query("Variable=='{}'".format(i)).sort_values(by=['Variable', 'WoE'], ascending=[True, False]))

"""### df_ideologia"""

# df_ideologia
df_ideologia_woe = pd.DataFrame(columns=['Variable', 'Value', 'X Frequency', 'Y Frequency', 'Rate', '% X', '% Y', '% Not Y', 'Risk Ratio', 'WoE', 'IV'])

variables = df_ideologia.columns.to_list()
variables.remove('frequency')
variables.remove('VAI_VACINAR')

for var in variables:
    aux = df_ideologia.groupby(by=var,as_index=False).agg({'frequency':'count','VAI_VACINAR':'sum'})
    x_frequency = aux['frequency'].sum()
    y_frequency = aux['VAI_VACINAR'].sum()
    not_y_frequency = x_frequency - y_frequency
    aux['Rate'] = aux['VAI_VACINAR'] / aux['frequency']
    aux['% X'] = aux['frequency']/x_frequency
    aux['% Y'] = aux['VAI_VACINAR']/y_frequency
    aux['% Not Y'] = (aux['frequency'] - aux['VAI_VACINAR'])/not_y_frequency
    aux['Risk Ratio'] = aux['% Y'] / aux['% Not Y']
    aux['WoE'] = np.log(aux['Risk Ratio'])
    aux['IV'] = ((1-aux['Rate']) - aux['Rate']) * aux['WoE']
    aux['Variable'] = var
    column_names = ['Variable', 'frequency', 'VAI_VACINAR', 'Rate', '% X', '% Y', '% Not Y', 'Risk Ratio', 'WoE', 'IV']
    column_names.insert(1,var)
    aux = aux[column_names]
    aux.columns = ['Variable', 'Value', 'X Frequency', 'Y Frequency', 'Rate', '% X', '% Y', '% Not Y', 'Risk Ratio', 'WoE', 'IV']
    df_ideologia_woe = df_ideologia_woe.append(aux, ignore_index=True)

cols_aux = df_ideologia_woe["Variable"].drop_duplicates()

for i in cols_aux:
  display(df_ideologia_woe.query("Variable=='{}'".format(i)))

df_ideologia_woe.query('Value==1').sort_values(by='WoE', ascending=False).reset_index(drop=True)

"""### df_avaliacao_governo"""

# df_avaliacao_governo
df_avaliacao_governo_woe = pd.DataFrame(columns=['Variable', 'Value', 'X Frequency', 'Y Frequency', 'Rate', '% X', '% Y', '% Not Y', 'Risk Ratio', 'WoE', 'IV'])

variables = df_avaliacao_governo.columns.to_list()
variables.remove('frequency')
variables.remove('VAI_VACINAR')

for var in variables:
    aux = df_avaliacao_governo.groupby(by=var,as_index=False).agg({'frequency':'count','VAI_VACINAR':'sum'})
    x_frequency = aux['frequency'].sum()
    y_frequency = aux['VAI_VACINAR'].sum()
    not_y_frequency = x_frequency - y_frequency
    aux['Rate'] = aux['VAI_VACINAR'] / aux['frequency']
    aux['% X'] = aux['frequency']/x_frequency
    aux['% Y'] = aux['VAI_VACINAR']/y_frequency
    aux['% Not Y'] = (aux['frequency'] - aux['VAI_VACINAR'])/not_y_frequency
    aux['Risk Ratio'] = aux['% Y'] / aux['% Not Y']
    aux['WoE'] = np.log(aux['Risk Ratio'])
    aux['IV'] = ((1-aux['Rate']) - aux['Rate']) * aux['WoE']
    aux['Variable'] = var
    column_names = ['Variable', 'frequency', 'VAI_VACINAR', 'Rate', '% X', '% Y', '% Not Y', 'Risk Ratio', 'WoE', 'IV']
    column_names.insert(1,var)
    aux = aux[column_names]
    aux.columns = ['Variable', 'Value', 'X Frequency', 'Y Frequency', 'Rate', '% X', '% Y', '% Not Y', 'Risk Ratio', 'WoE', 'IV']
    df_avaliacao_governo_woe = df_avaliacao_governo_woe.append(aux, ignore_index=True)

cols_aux = df_avaliacao_governo_woe["Variable"].drop_duplicates()

for i in cols_aux:
  display(df_avaliacao_governo_woe.query("Variable=='{}'".format(i)))

"""### df_opiniao_vacina"""

# df_opiniao_vacina
df_opiniao_vacina_woe = pd.DataFrame(columns=['Variable', 'Value', 'X Frequency', 'Y Frequency', 'Rate', '% X', '% Y', '% Not Y', 'Risk Ratio', 'WoE', 'IV'])

variables = df_opiniao_vacina.columns.to_list()
variables.remove('frequency')
variables.remove('VAI_VACINAR')

for var in variables:
    aux = df_opiniao_vacina.groupby(by=var,as_index=False).agg({'frequency':'count','VAI_VACINAR':'sum'})
    x_frequency = aux['frequency'].sum()
    y_frequency = aux['VAI_VACINAR'].sum()
    not_y_frequency = x_frequency - y_frequency
    aux['Rate'] = aux['VAI_VACINAR'] / aux['frequency']
    aux['% X'] = aux['frequency']/x_frequency
    aux['% Y'] = aux['VAI_VACINAR']/y_frequency
    aux['% Not Y'] = (aux['frequency'] - aux['VAI_VACINAR'])/not_y_frequency
    aux['Risk Ratio'] = aux['% Y'] / aux['% Not Y']
    aux['WoE'] = np.log(aux['Risk Ratio'])
    aux['IV'] = ((1-aux['Rate']) - aux['Rate']) * aux['WoE']
    aux['Variable'] = var
    column_names = ['Variable', 'frequency', 'VAI_VACINAR', 'Rate', '% X', '% Y', '% Not Y', 'Risk Ratio', 'WoE', 'IV']
    column_names.insert(1,var)
    aux = aux[column_names]
    aux.columns = ['Variable', 'Value', 'X Frequency', 'Y Frequency', 'Rate', '% X', '% Y', '% Not Y', 'Risk Ratio', 'WoE', 'IV']
    df_opiniao_vacina_woe = df_opiniao_vacina_woe.append(aux, ignore_index=True)

cols_aux = df_opiniao_vacina_woe["Variable"].drop_duplicates()

for i in cols_aux:
  display(df_opiniao_vacina_woe.query("Variable=='{}'".format(i)))

df_opiniao_vacina_woe.query('Value==0').sort_values(by='WoE', ascending=False).reset_index(drop=True)



esc_mapping = {'ANALFABETO':1,
               'FUNDAMENTAL_1':0,
               'FUNDAMENTAL_2':1,
               'SUPERIOR_COMPLETO':0,
               'SUPERIOR_INCOMPLETO':1}
df_antivac=df_renomeado.copy()
df_antivac['escolaridade_anti_vac'] = df_antivac['ESCOLARIDADE'].map(esc_mapping)

df_antivac['religiao_anti_vac']=[1 if i=='EVANGELICA' else 0 for i in df_antivac["RELIGIAO"]]
df_antivac['idade_anti_vac']=[1 if i<41 else 0 for i in df_antivac["IDADE"]]
df_antivac['renda_anti_vac']=[1 if i=="ATE_1" else 0 for i in df_antivac["RENDA_PESSOAL"]]


df_antivac['anti_vac'] = df_antivac['religiao_anti_vac']*df_antivac["APROVA_GOVERNO"]

df_antivac['frequency']=1

var="anti_vac"
aux = df_antivac.groupby(by=var,as_index=False).agg({'frequency':'count','VAI_VACINAR':'sum'})
x_frequency = aux['frequency'].sum()
y_frequency = aux['VAI_VACINAR'].sum()
not_y_frequency = x_frequency - y_frequency
aux['Rate'] = aux['VAI_VACINAR'] / aux['frequency']
aux['% X'] = aux['frequency']/x_frequency
aux['% Y'] = aux['VAI_VACINAR']/y_frequency
aux['% Not Y'] = (aux['frequency'] - aux['VAI_VACINAR'])/not_y_frequency
aux['Risk Ratio'] = aux['% Y'] / aux['% Not Y']
aux['WoE'] = np.log(aux['Risk Ratio'])
aux['IV'] = ((1-aux['Rate']) - aux['Rate']) * aux['WoE']
aux['Variable'] = var
column_names = ['Variable', 'frequency', 'VAI_VACINAR', 'Rate', '% X', '% Y', '% Not Y', 'Risk Ratio', 'WoE', 'IV']
column_names.insert(1,var)
aux = aux[column_names]
aux.columns = ['Variable', 'Value', 'X Frequency', 'Y Frequency', 'Rate', '% X', '% Y', '% Not Y', 'Risk Ratio', 'WoE', 'IV']
aux

# Biblioteca para pré processamento dos dados
from sklearn.decomposition import PCA

# Aplica PCA para uma melhor visualização dos dados
pca_data = PCA(n_components = 2).fit_transform(df_renomeado_dummies)

# Plota os dados em relação às duas componentes
plt.figure(figsize = (10, 8))
plt.scatter(pca_data[:, 0], pca_data[:, 1])
plt.xlabel('PC1')
plt.ylabel('PC2')
plt.title('Distribuição dos Dados - Componentes Principais 1 e 2', size = 16)

"""## df_ideologia predict_proba"""

# for i in range(2,10):
#   clf = RandomForestClassifier(n_estimators=100, max_leaf_nodes=i)
#   clf = clf.fit(X_train, y_train)
#   print('max_leaf_nodes: ' + str(i) + " auc:" + str(roc_auc_score(y_train, clf.predict_proba(X_train)[:,1])))
#   print('max_leaf_nodes: ' + str(i) + " auc:" + str(roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])))

X_train, X_test, y_train, y_test = train_test_split(df_renomeado_dummies.drop(columns='VAI_VACINAR'), df_renomeado_dummies['VAI_VACINAR'], test_size=0.3, random_state=42)

columns_to_keep = ['VOTO_CIRO', 'VOTO_HADDAD', 'VOTO_LULA', 'VOTO_HUCK', 'VOTO_BOLSONARO', 'VOTO_DORIA', 'VOTO_MORO', 'VOTO_MANDETTA', 'VOTO_BOULOS', 'VOTO_MARINA']
X_train_ideo = X_train[columns_to_keep]
X_test_ideo = X_test[columns_to_keep]

# fits rfc
#X_train, X_test, y_train, y_test = train_test_split(df_ideologia.drop(columns='VAI_VACINAR'), df_ideologia['VAI_VACINAR'], test_size=0.3, random_state=42)
rfc = RandomForestClassifier(n_estimators=100, max_leaf_nodes=7,max_depth=3)
rfc = rfc.fit(X_train_ideo, y_train)
print('[Train] AUC ROC Score: ' + str(roc_auc_score(y_train, rfc.predict_proba(X_train_ideo)[:,1])))
print('[Test] AUC ROC Score: ' + str(roc_auc_score(y_test, rfc.predict_proba(X_test_ideo)[:,1])))

# concat predict proba to train/test data
X_train['score_ideologia'] = rfc.predict_proba(X_train_ideo)[:,1]
X_test['score_ideologia'] = rfc.predict_proba(X_test_ideo)[:,1]

# append test data to train data - this way we can have a single dataframe in order to sort and join
#X_train.append(X_test_ideo)
#X_train.sort_index(inplace=True)

# copy dataframe
#df_renomeado_tratado = df_renomeado.copy()
#df_renomeado_dummies_tratado = df_renomeado_dummies.copy()

# drop the columns that we won't need anymore
#columns_to_drop = ['VOTO_CIRO', 'VOTO_HADDAD', 'VOTO_LULA', 'VOTO_HUCK', 'VOTO_BOLSONARO', 'VOTO_DORIA', 'VOTO_MORO', 'VOTO_MANDETTA', 'VOTO_BOULOS', 'VOTO_MARINA']
#df_renomeado_tratado.drop(columns=columns_to_drop, inplace=True)
#df_renomeado_dummies_tratado.drop(columns=columns_to_drop, inplace=True)

# join the predict proba column
#df_renomeado_tratado['predict_proba'] = X_train['predict_proba']
#df_renomeado_dummies_tratado['predict_proba'] = X_train['predict_proba']



auc_arvores=[]
for i in range(len(rfc.estimators_)):
  #print(i)
  aux=rfc.estimators_[i]
  aux2=roc_auc_score(y_test, aux.predict_proba(X_test_ideo)[:,1])
  auc_arvores.append(aux2)

arvore_escolhida=np.argmax(auc_arvores)
print(arvore_escolhida)
print(max(auc_arvores))
# plot
from sklearn import tree

plt.figure(figsize=(12, 12))
tree.plot_tree(rfc.estimators_[arvore_escolhida], fontsize=10, rounded=True, filled=True, feature_names=X_train_ideo.columns,proportion=True,class_names=True)
plt.show()

plt.figure(figsize=(12, 12))
tree.plot_tree(rfc.estimators_[40], fontsize=10, rounded=True, filled=True, feature_names=X_train_ideo.columns,proportion=True,class_names=True)
plt.show()

cols_woe=[]
result=df_renomeado.copy()

df_avaliacao_governo_woe
df_perfil_woe


cols_aux = df_opiniao_vacina_woe["Variable"].drop_duplicates()
for i in cols_aux:
  aux = df_opiniao_vacina_woe.query("Variable=='{}'".format(i))[["Value","WoE"]]
  aux.columns=["Value",i+"_woe"]
  cols_woe.append(i+"_woe")
  #print(df_renomeado[i])
  #print(aux["Value"])
  print(i)
  result = pd.merge(result, aux, left_on=i, right_on="Value", how="outer")

cols_aux = df_avaliacao_governo_woe["Variable"].drop_duplicates()
for i in cols_aux:
  aux = df_avaliacao_governo_woe.query("Variable=='{}'".format(i))[["Value","WoE"]]
  aux.columns=["Value",i+"_woe"]
  cols_woe.append(i+"_woe")
  #print(df_renomeado[i])
  #print(aux["Value"])
  print(i)
  result = pd.merge(result, aux, left_on=i, right_on="Value", how="outer")

cols_aux = df_perfil_woe["Variable"].drop_duplicates()
for i in cols_aux:
  aux = df_perfil_woe.query("Variable=='{}'".format(i))[["Value","WoE"]]
  aux.columns=["Value",i+"_woe"]
  cols_woe.append(i+"_woe")
  #print(df_renomeado[i])
  #print(aux["Value"])
  print(i)
  result = pd.merge(result, aux, left_on=i, right_on="Value", how="outer")


correlation = correlation = result[cols_woe].corr()

plt.figure(figsize=(15,15))

sns.heatmap(correlation, annot = True, fmt=".1f", linewidths=.6)

X_train.columns

"""## Feature importance"""

# train_test_split
#X_train, X_test, y_train, y_test = train_test_split(df_renomeado_dummies_tratado.drop(columns=['IDADE','VAI_VACINAR']), df_renomeado_dummies_tratado['VAI_VACINAR'], test_size=0.3, random_state=42)
columns_to_drop= ['VOTO_CIRO', 'VOTO_HADDAD', 'VOTO_LULA', 'VOTO_HUCK', 'VOTO_BOLSONARO',
                  'VOTO_DORIA', 'VOTO_MORO', 'VOTO_MANDETTA', 'VOTO_BOULOS', 'VOTO_MARINA','IDADE','CONFIA_BOLSONARO',
                  'RENDA_FAMILIAR_2_A_5','RENDA_FAMILIAR_5_MAIS', 'RENDA_FAMILIAR_ATE_1', 'RENDA_FAMILIAR_N/A']

X_train_trat = X_train.drop(columns=columns_to_drop,inplace=False)
X_test_trat = X_test.drop(columns=columns_to_drop,inplace=False)

etc = ExtraTreesClassifier(n_estimators=100)
etc = etc.fit(X_train_trat, y_train)
etc.feature_importances_
sorted_idx = etc.feature_importances_.argsort()
plt.figure(figsize=(15,15))
plt.barh(X_train_trat.columns[sorted_idx], etc.feature_importances_[sorted_idx])
plt.title("Random Forest Feature Importance")
plt.xlabel("Feature Importance")

#VACINA SEGURA
#score_ideologia
#SEXO_MASC
#TRAT_MAIS_EFIC
#RENDA PESSOAL
#APROVA_GOVERNO
#REG
#FXIDADE
#ESCOLARIDADE
#Religiao



"""## Step forward"""

#forward_feature_selector = SequentialFeatureSelector(RandomForestClassifier(n_jobs=-1), n_features_to_select=10, direction='forward', scoring='roc_auc')
#fselector = forward_feature_selector.fit(X_train, y_train)
#fselector.get_feature_names_out()

"""## Step backawrd"""

#backward_feature_selector = SequentialFeatureSelector(RandomForestClassifier(n_jobs=-1), n_features_to_select=10, direction='backward', scoring='roc_auc')
#bselector = backward_feature_selector.fit(X_train, y_train)
#bselector.get_feature_names_out()

"""# Classification Model"""

#VACINA SEGURA
#score_ideologia
#SEXO_MASC
#TRAT_MAIS_EFIC
#REG
#FXIDADE
#APROVA_GOVERNO
#ESCOLARIDADE

X_train_trat.columns

# train_test_split
#X_train, X_test, y_train, y_test = train_test_split(df_renomeado_dummies_tratado.drop(columns=['IDADE','VAI_VACINAR']), df_renomeado_dummies_tratado['VAI_VACINAR'], test_size=0.3, random_state=42)
columns_to_keep= ['APROVA_GOVERNO', 'VACINA_SEGURA', 'TRAT_MAIS_EFIC',
       'FXIDADE_29_A_41','FXIDADE_42_A_54', 'FXIDADE_54_MAIS', 'SEXO_MAS',
       'ESCOLARIDADE_FUNDAMENTAL_1', 'ESCOLARIDADE_FUNDAMENTAL_2',
       'ESCOLARIDADE_SUPERIOR_COMPLETO', 'ESCOLARIDADE_SUPERIOR_INCOMPLETO',
       'RELIGIAO_AGNOSTICO', 'RELIGIAO_ATEU', 'RELIGIAO_CATOLICA',
       'RELIGIAO_ESPIRITA', 'RELIGIAO_EVANGELICA', 'RELIGIAO_N/A',
       'RELIGIAO_OUTRAS', 'RENDA_PESSOAL_2_A_5', 'RENDA_PESSOAL_5_MAIS',
       'RENDA_PESSOAL_ATE_1', 'RENDA_PESSOAL_N/A',
       'RENDA_PESSOAL_SEM_RENDA_PESSOAL', 'REG_NORTE_CENTRO_OESTE',
       'REG_SUDESTE', 'REG_SUL', 'score_ideologia']

X_train_final = X_train_trat[columns_to_keep]
X_test_final = X_test_trat[columns_to_keep]

# fits rfc
#X_train, X_test, y_train, y_test = train_test_split(df_ideologia.drop(columns='VAI_VACINAR'), df_ideologia['VAI_VACINAR'], test_size=0.3, random_state=42)
rfc = RandomForestClassifier(n_estimators=100, max_leaf_nodes=7,max_depth=3)
rfc = rfc.fit(X_train_final, y_train)
print('[Train] AUC ROC Score: ' + str(roc_auc_score(y_train, rfc.predict_proba(X_train_final)[:,1])))
print('[Test] AUC ROC Score: ' + str(roc_auc_score(y_test, rfc.predict_proba(X_test_final)[:,1])))

from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import confusion_matrix
print('[Train] Precision Score: ' + str(precision_score(y_train, (rfc.predict(X_train_final)))))
print('[Test]  Precision Score: ' + str(precision_score(y_test, (rfc.predict(X_test_final)))))
print('[Train] Recall Score: ' + str(recall_score(y_train, (rfc.predict(X_train_final)))))
print('[Test]  Recall Score: ' + str(recall_score(y_test, (rfc.predict(X_test_final)))))
print("[Train]  Confusion Matrix")
print(confusion_matrix(y_train, (rfc.predict(X_train_final))))
print("[Test]  Confusion Matrix")
print(confusion_matrix(y_test, (rfc.predict(X_test_final))))

auc_arvores=[]
for i in range(len(rfc.estimators_)):
  #print(i)
  aux=rfc.estimators_[i]
  aux2=roc_auc_score(y_test, aux.predict_proba(X_test_final)[:,1])
  auc_arvores.append(aux2)

arvore_escolhida=np.argmax(auc_arvores)
#print(arvore_escolhida)
#print(max(auc_arvores))
# plot
from sklearn import tree

plt.figure(figsize=(12, 12))
tree.plot_tree(rfc.estimators_[arvore_escolhida], fontsize=10, rounded=True, filled=True, feature_names=X_train_final.columns,proportion=True,class_names=True)
plt.show()

plt.figure(figsize=(12, 12))
tree.plot_tree(rfc.estimators_[77], fontsize=10, rounded=True, filled=True, feature_names=X_train_final.columns,proportion=True,class_names=True)
plt.show()